#Lav predictions
test$PredictionsLogit <- predict(newlm1, test)
#Make log into percent, to resemble probabilties.
test$PredictionsPerc <- inv.logit(test$PredictionsLogit)
test$PredictionsPerc=predict(newlm1)
test$Predictions[test$PredictionsPerc>0.5]="0"
test$Predictions[test$PredictionsPerc<=0.5]="1"
testpred<- confusionMatrix(test = test$Predictions, reference = test$diagnosis, positive = "1")
print(testpred)
#Lav predictions
train$PredictionsLogit <- predict(newlm1, train)
#Make log into percent, to resemble probabilties.
schiData$PredictionsPerc <- inv.logit(train$PredictionsLogit)
train$PredictionsPerc=predict(newlm1)
train$Predictions[test$PredictionsPerc>0.5]="0"
train$Predictions[test$PredictionsPerc<=0.5]="1"
trainpred <- confusionMatrix(train = train$Predictions, reference = train$diagnosis, positive = "1") #Get the     predicitons for the test set (from the model just fit on the rmse train data)
print(trainpred) #show error of model
#Få data ud af conmatrix, accuracy, sensitivty, ... osv.
#Get the     predicitons for the test set (from the model just fit on the rmse train data)
#show error of model
#Save model error as values
testvalues1[n]=(testpred)
trainvalues1[n]=(trainpred)
n = n+1
}
CrossVal <- data.frame(testvalues1)
#Find mean and SE for test and train data
# mean(testvalues1)
# sd(testvalues1)/sqrt(length(testvalues1))
#
# mean(trainvalues1)
# sd(trainvalues1)/sqrt(length(trainvalues1))
# Chunk 6
# Chunk 7
#
# Chunk 8
#combine predictors i've tried in question 3
# Chunk 9
#we used these methods
#We compared models
#X model was best, this is the performance of the model
#Look at sensitivuty and specificity. If sensitivity is higher than specificity it's
#
newlm1 <- glm(diagnosis ~ range + (1|study), schiData, family = "binomial") #Get your new linear mo
test$PredictionsLogit <- predict(newlm1, test)
#Få data ud af conmatrix, accuracy, sensitivty, ... osv.
#_______________________________________________________________________________________
#TEST model on test data
test$PredictionsLogit <- predict(newlm1, test)
install.packages(knitr)
install.packages("knitr")
install.packages("knitr")
install.packages("knitr")
install.packages("knitr")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
setwd("~/R/R - Datascripts/Assignment 3")
#Load library
library(ggplot2);library(pastecs);library(rmarkdown);library(tidyr);
library(dplyr);library(QuantPsyc);library(VIF);library(stringr);library(tidytext);library(DHARMa);library(lme4);library(psych);library(MuMIn);library(tidyverse);library(magrittr);library(Metrics);library(simr);library(readtext);library(crqa);library(readr);library(Hmisc);library(lmerTest)
library(caret);library(gtools)
#install.packages("e1071", dependencies = TRUE)
#install.packages("base64enc", dependencies = TRUE)
#Load dataset from part 1
schiData <- read.delim('dataExtractSchizo.csv', sep = ",")
# Chunk 3
#Can you predict schizophrenia with pitch?
D ~ Pitch + (..)
str(df)
diagnosisModel <- glmer(diagnosis ~ 1 + scale(range) + (1|study), schiData, family = "binomial")
summary(diagnosisModel)
# Chunk 4
#install.packages("gtools")
#
#Lav predictions
schiData$PredictionsLogit <- predict(diagnosisModel)
#Make log into percent, to resemble probabilties.
schiData$PredictionsPerc <- inv.logit(schiData$PredictionsLogit)
#Confmatrix
schiData$PredictionsPerc=predict(diagnosisModel)
schiData$Predictions[schiData$PredictionsPerc>0.5]="0"
schiData$Predictions[schiData$PredictionsPerc<=0.5]="1"
confusionMatrix(data = schiData$Predictions, reference = schiData$diagnosis, positive = "1")
# Chunk 5
schiData$SUBJ <- as.numeric(factor(schiData$participant))
#Crossvalidate. Turn lmer into glmer, turn root/square mean (rmse) error into confmatrix and rocCurve.
k <- 10 #the number of folds. 10-fold cross validation.We break up ASDdata set into 10 folds, call each fold the testing set and build the model on the other 9.
schi_folds <- createFolds(unique(schiData$participant, k=k))#unique assures that no 'leakage' happens (leakage: that a child is in both training and testing)
str(pitch)
testvalues1 = NULL
trainvalues1 = NULL
n = 1
for(i in 1:k){
test <- subset(schiData, (SUBJ %in% schi_folds[[i]])) #find all subjects in ASD data, look in all foldere for these children in folders [in[in]]
train<- subset(schiData, !(SUBJ %in% schi_folds[[i]])) #Do the opposite
#Train model on train data
newlm1 <- glm(diagnosis ~ range + (1|study), schiData, family = "binomial") #Get your new linear model (just fit on the train data)
#Train model on data
#Lav predictions
train$PredictionsLogit <- predict(newlm1, train)
#Make log into percent, to resemble probabilties.
schiData$PredictionsPerc <- inv.logit(train$PredictionsLogit)
train$PredictionsPerc=predict(newlm1)
train$Predictions[test$PredictionsPerc>0.5]="0"
train$Predictions[test$PredictionsPerc<=0.5]="1"
trainpred <- confusionMatrix(train = train$Predictions, reference = train$diagnosis, positive = "1") #Get the     predicitons for the test set (from the model just fit on the rmse train data)
print(trainpred) #show error of model
#Få data ud af conmatrix, accuracy, sensitivty, ... osv.
#_______________________________________________________________________________________
#TEST model on test data
test$PredictionsLogit <- predict(newlm1, test)
#Make log into percent, to resemble probabilties.
test$PredictionsPerc <- inv.logit(test$PredictionsLogit)
test$PredictionsPerc=predict(newlm1)
test$Predictions[test$PredictionsPerc>0.5]="0"
test$Predictions[test$PredictionsPerc<=0.5]="1"
testpred<- confusionMatrix(test = test$Predictions, reference = test$diagnosis, positive = "1")
print(testpred)
#Save model error as values
testvalues1[n]=(testpred)
trainvalues1[n]=(trainpred)
n = n+1
}
CrossVal <- data.frame(testvalues1)
#Find mean and SE for test and train data
# mean(testvalues1)
# sd(testvalues1)/sqrt(length(testvalues1))
#
# mean(trainvalues1)
# sd(trainvalues1)/sqrt(length(trainvalues1))
#Only report the best model from the test data results. Only report the test data.
# Chunk 6
# Chunk 7
#
# Chunk 8
#combine predictors i've tried in question 3
# Chunk 9
#we used these methods
#We compared models
#X model was best, this is the performance of the model
#Look at sensitivuty and specificity. If sensitivity is higher than specificity it's
#
schiData$PredictionsLogit <- predict(diagnosisModel)
#Make log into percent, to resemble probabilties.
schiData$PredictionsPerc <- inv.logit(schiData$PredictionsLogit)
#Confmatrix
schiData$PredictionsPerc=predict(diagnosisModel)
schiData$Predictions[schiData$PredictionsPerc>0.5]="0"
schiData$Predictions[schiData$PredictionsPerc<=0.5]="1"
confusionMatrix(data = schiData$Predictions, reference = schiData$diagnosis, positive = "1")
schiData$SUBJ <- as.numeric(factor(schiData$participant))
rocCurve.
k <- 10 #the number of folds. 10-fold cross validation.We break up ASDdata set into 10 folds, call each fold the testing set and build the model on the other 9.
schi_folds <- createFolds(unique(schiData$participant, k=k))#unique assures that no 'leakage'
testvalues1 = NULL
trainvalues1 = NULL
n = 1
for(i in 1:k){
test <- subset(schiData, (SUBJ %in% schi_folds[[i]])) #find all subjects in ASD data, look in all foldere for these children in folders [in[in]]
train<- subset(schiData, !(SUBJ %in% schi_folds[[i]])) #Do the opposite
for(i in 1:k){
test <- subset(schiData, (SUBJ %in% schi_folds[[i]])) #find all subjects in ASD data, look in all foldere for these children in folders [in[in]]
train<- subset(schiData, !(SUBJ %in% schi_folds[[i]])) #Do the opposite
#Train model on train data
newlm1 <- glm(diagnosis ~ range + (1|study), schiData, family = "binomial") #Get your new linear model (just fit on the train data)
}
for(i in 1:k){
test <- subset(schiData, (SUBJ %in% schi_folds[[i]])) #find all subjects in ASD data, look in all foldere for these children in folders [in[in]]
train<- subset(schiData, !(SUBJ %in% schi_folds[[i]])) #Do the opposite
#Train model on train data
newlm1 <- glm(diagnosis ~ range + (1|study), schiData, family = "binomial") #Get your new linear model (just fit on the train data)
}
summary(newlm1)
diagnosisModel <- glmer(diagnosis ~ 1 + scale(range) + (1|study), schiData, family = "binomial")
summary(diagnosisModel)
newlm1 <- glm(diagnosis ~ 1+ range + (1|study), schiData, family = "binomial") #Get your new linear model (just fit on the train data)
summary(newlm1)
on train data
glmModel <- glmer(diagnosis ~ 1 + scale(range) + (1|study), schiData, family = "binomial")
summary(glmModel)
for(i in 1:k){
test <- subset(schiData, (SUBJ %in% schi_folds[[i]])) #find all subjects in ASD data, look in all foldere for these children in folders [in[in]]
train<- subset(schiData, !(SUBJ %in% schi_folds[[i]])) #Do the opposite
#Train model on train data
glmModel <- glmer(diagnosis ~ 1 + scale(range) + (1|study), schiData, family = "binomial")
summary(glmModel)#Get your new linear model (just fit on the train data)
#Train model on data
#Lav predictions
train$PredictionsLogit <- predict(newlm1, train)
#Make log into percent, to resemble probabilties.
schiData$PredictionsPerc <- inv.logit(train$PredictionsLogit)
train$PredictionsPerc=predict(newlm1)
train$Predictions[test$PredictionsPerc>0.5]="0"
train$Predictions[test$PredictionsPerc<=0.5]="1"
trainpred <- confusionMatrix(train = train$Predictions, reference = train$diagnosis, positive = "1") #Get the     predicitons for the test set (from the model just fit on the rmse train data)
print(trainpred) #show error of model
}
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
#Set directory
setwd("~/R/R - Datascripts/Assignment 3")
#Load library
library(ggplot2);library(pastecs);library(rmarkdown);library(tidyr);
library(dplyr);library(QuantPsyc);library(VIF);library(stringr);library(tidytext);library(DHARMa)
library(lme4);library(lmerTest);library(psych);library(MuMIn);library(tidyverse);library(magrittr);library(Metrics);library(caret);library(simr);library(readtext);library(crqa);library(readr)
#Load dataset from part 1
Artic = read.delim('Articulation.txt', sep = ',')
DemoData = read.delim('DemoData.txt', sep = '.')
Pitch1 = read.table("~/R/R - Datascripts/Assignment 3/Pitch/Study1D0S101T1_f0.txt", header=T)
#Load data
files = list.files(path = "~/R/R - Datascripts/Assignment 3/Pitch",pattern="*.txt")
print(files)
#Artic data. 0 means control, 1 = Schizo. Number after 0 and 1 identifies two similiarly matched participants. They have similiar traits, so schizo is matched with a control.
#T 1, 2, 3 = video 1 they have to describe, video 2 etc
#
# Chunk 3
#Extract "standard" descriptors
range(Pitch1$f0)
mean(Pitch1$f0)
sd(Pitch1$f0)
range(Pitch1$time)
mean(Pitch1$time)
sd(Pitch1$time)
#Frequency M = 139,92, SD = 31,38, 142,01.
#Extract "less standard"
stat.desc(Pitch1)
#Frequency median = 125,59, SE = 2,47, Coef.var = 0,224.
#Extract "complex descriptors".
#Delay parameter threshold(T); can be estimated using the mutual average information function.
#T is the basis of unfolding the one-dimensional time-series into a multidimensional phase-space.
library(tseriesChaos)
# run Average Mutual Information
mutual(Pitch1$f0, lag.max = 50)
#I chose the lowest value in my AMI plot to make the most conservative analysis. T = 22.
# Embedding parameter D; can be estimated using the false-nearest neighbor function.
# If D = 1, we do not need to embed.
# If D > 1, we want to unfold the one-dimensional time-series into as many dimensions so that we exhaust all information about higher-dimensional dynamics contained in the time-series, but not more.
# m: embedding dimension D
# d: delay T
# t: an additional parameter, the Theiler-window, that can help to increase the reliability of the false-nearest neighbor analysis and recurrence statistics by removing unwanted short-term temporal correlations.
# run false-nearestneighbor analysis
fnn = false.nearest(Pitch1$f0, m=5, d=22, t=0)
plot(fnn)
#Install package
#install.packages("crqa")
# ??crqa
mlpar = list(lgM =  35, radiusspan = 400, radiussample = 10, normalize = 0, rescale = 1, mindiagline = 2,
minvertline = 2, tw = 0, whiteline = FALSE, recpt = FALSE, fnnpercent = 10, typeami = "maxlag")
optpar <- optimizeParam(Pitch1,Pitch1,mlpar); optpar
#I find the parameters for my crqa model:
#
Results <- try(crqa(Pitch1, Pitch1, embed = 3, delay = 30, radius = 2, normalize = 0, rescale = 2, mindiagline = 2, minvertline = 2))
Results
RP=Results$RP
RP = matrix(as.numeric(RP), nrow = ncol(RP))
cols = c("white","blue4")
image(RP, xlab = "", ylab = "", col = cols)
#Falsen
#RR
#Delay
#Package, function Mutual(), tells muttual information. Tells how easy it is to predict the next datapoints. How strongly correlated two points in time. Trying to predict two points in the future, less correlation. So it should increase over time. We should try to find the optimal delay. Take the minium possible delay, really conservative and removes some data.
#Second way we look at when the slopes changes between data lines, so down, down, down, up. We stopå here.Less conservative, keeps more data.
#Use optimizeparam function. Will always pick the most conservative. Will give error embed*delay longer than tsm. We plot in timeseries in x-axis, but because we add a delay in y axis. We have to add x-time ontop of the x-axis time. We end up removing lots of data. If we use try() around it, it will run it and remove these.
#Use CRQA()
# Chunk 4
#List all files
#Make loop
#The simplest loop
#Calculate mean, SD, and run crqa
Mp = NULL
SDp = NULL
radius = NULL
embed = NULL
delay = NULL
N = 1
files <- list.files(path = "~/R/R - Datascripts/Assignment 3/Pitch", pattern="*.txt")
for (i in files) {
#Can use read_csv with ReadR package. Will read txt files aswell.
x = read.table(i, header = T)
#When did we record the pitch. We care about the F0 (pitch), we don't care about time. Drop time from x.
#x = x$F0
}
Mp[N]= mean(x, na.rm = T)
SDp[N] = SD(x,na.rm = T)
#It's best to start from one
N = N +1
#We want to save each loop in a dataframe: Mean and SD as columns.
#We first create these variables.
#We create empty variables
#LOOK AT REGULAR EXPRESSIONS - Regex.
#Extract ID. Use a stringer extract strings, Use package StringR
#Create new empty variable
particpant = Null
ID = str_extract(i, "S+\\d+")#in i find big S (string), like find S102 (study S102) \\ regular expression, search for digits, + means look for mulitple digtigts. Tell it look in files. Problem using S102, subjects ID's is not more meaningful as digits.
particpant[n] = str_extract(ID, "\\d+") #Use ID, it will look for ID numbers digits.
#use above code (kinda) to extract Diagnosis.
mlpar = list(lgM =  35, radiusspan = 400, radiussample = 10, normalize = 0, rescale = 1,     mindiagline = 2,
minvertline = 2, tw = 0, whiteline = FALSE, recpt = FALSE, fnnpercent = 10, typeami = "maxlag")
#RQUA, find Delay, Embed and Radius. Use optimize function optimizeparam()
#One school of thought: Unfold the timephase in the best phasespace.
#Other school of thought: You need to choose the same Delay, Embed and Radius for all timeseries. You want to maximise comparability of timeseries.
#Both work.
#Always argue for your choice of extracting paramters!
#output of optimize.
#Issues with optimizeParam(). There's 3 dimensions Ex. Embed is longer than delay in timeseries. Embed could be 3, delay 50 and timeseries 1 sec.
#We want to put timeseries on both axis. If it's a 100 secons, we have to throw everything above 100 on y and x-axis away. On the third dimension, we have to delay. Problem we want to set it to 101, but there is none, so it throws everything away.
#There is a paramter in optimize lgM, means lag maximum. Use 15. They found the lag by testing numbers in files above 100, that kept most data. Ex. if you record a voice with a microphone, the vibrations from first test could continue slightly into the second, polluting data. So you find a cutoff.
#When we look at recurrence plot thats' either blank or black, we can't read anything from it.
#Recurrence rate is discontinous. Sometimes you can't optimize paramters, you can try and relax the min and max radius. Less precise comparability between min and max if there's a larger difference.
#Use min.Rec = 3 and max.rec = 5
#If we look at the plot and get a black square around 0.4,
#A = optimizeParam(x,x, mlpar)
#If you get embed*delay error shows up, use try(). This makes the loop continue and doesn't crash. You want the loop to keep running if it gets an error.
A = try(optimizeParam(x,x,mlpar))
if(length(A)<2{
delay[N] = NA #Delay of datapoints
embed[N] = NA
radius[N] = NA
})
else(delay[N] = A$Delay)
}
#After loop write into dataframe
Df = data.frame(participant, Mp, SDp)
#Save delay and embed and radius into a dataframe. Now you have optimal paramters.
#You now find a delay, embed and radius for all files.
#So find median for all delays
Delay = Mean(Df$Delay, na.rm = TRUE)
#You can build a second loop just find CRQA information and save into dataframe for each files
#After loop write into dataframe.
#Second loop would look like this
for (i in files) {
#Can use read_csv with ReadR package. Will read txt files aswell.
x = read.table(i)
x = x$F0
# When did we record the pitch. We care about the F0 (pitch), we don't care about time. Drop time from x.
# Use paramters found in the first loop
CRQA(x,x...)
RR[N] = A$Rec
DET[N] = A$DET
# Write into a csv file
write.csv(dataframe, file = "filenamewhatever.csv")
}
# Chunk 5
#Extract list of files
files = list.files(path = "~/R/R - Datascripts/Assignment 3/Pitch",pattern="*.txt")
#setWD
setwd("~/R/R - Datascripts/Assignment 3/Pitch")
participant = NULL
diagnosis = NULL
trial = NULL
study = NULL
delay = NULL
radius = NULL
embed = NULL
n = 1
#Extract optimal parameters
for (file in files){
#print(file)
#read the specific file
tempFile = read.table(file, header = T)
#get participant number information
#would like to extract seperate participant, trial and diagnosis info
study[n] = substring(file, 6, 6)
diagnosis[n] = substring(file, 8, 8)
participant[n] = substring(sub("T.*", "", file),8)
trial[n] = sub(".T*", "", sub("\\_.*", "", sub("^[^T]*", "", file)))
#optimizeparam functions
par = list(lgM = 50, steps = seq(1, 6, 1), radiusspan = 100, radiussample = 40, normalize = 0, rescale = 0, mindiagline = 2, minvertline = 2, tw = 0, whiteline = F, recpt = FALSE, fnnpercent = 10, typeami = "mindip")
ans = try(optimizeParam(tempFile$f0, tempFile$f0, par))
#print(ans)
#if statement: If having problem with optimizeparam, it will append NA
if (length(ans) > 1){
radius[n] = ans[1]
embed[n] = ans[2]
delay[n] = ans[3]
}
else {
radius[n] = NA
embed[n] = NA
delay[n] = NA
}
n = n+1
print(n)
}
#Report area under curve, rocCurve
install.packages("plotRoc")
#Report area under curve, rocCurve
install.packages("plotROC")
train$PredictionsLogit <- predict(newlm1, train)
glmModel <- glmer(diagnosis ~ 1 + scale(range) + (1|study), schiData, family = "binomial")
summary(glmModel)#Get your new linear model (just fit on the train data)
#Train model on data
#Lav predictions
train$PredictionsLogit <- predict(newlm1, train)
#Make log into percent, to resemble probabilties.
#schiData$PredictionsPerc <- inv.logit(train$PredictionsLogit)
#train$PredictionsPerc=predict(newlm1)
train$Predictions[train$PredictionsLogit>0]="0"
train$Predictions[train$PredictionsLogit<=0]="1"
trainpred <- confusionMatrix(train = train$Predictions, reference = train$diagnosis, positive =   "1") #Get the     predicitons for the test set (from the model just fit on the rmse train data)
train$PredictionsLogit <- predict(newlm1, train)
train$PredictionsLogit <- predict(glmModel, train)
#Make log into percent, to resemble probab
train$Predictions[train$PredictionsLogit>0]="0"
train$Predictions[train$PredictionsLogit<=0]="1"
trainpred <- confusionMatrix(train = train$Predictions, reference = train$diagnosis, positive =   "1") #Get the     predicitons for the test
?confusionMatrix
trainpred <- confusionMatrix(data = train$Predictions, reference = train$diagnosis, positive =   "1") #Get the     predicitons for the
et the     predicitons for the test set (from the model just fit on the rmse train data)
print(trainpred) #show error of model
?rocCurve
?plotROC
??plotROC
vignette("examples", package = "plotROC")
styledplot <- basicplot + style_roc()
styledplot
styledplot <- basicplot + style_roc()
confu<- confusionMatrix(data = schiData$Predictions, reference = schiData$diagnosis, positive = "1")
#Lav predictions
schiData$PredictionsLogit <- predict(diagnosisModel)
#Make log into percent, to resemble probabilties.
schiData$PredictionsPerc <- inv.logit(schiData$PredictionsLogit)
#Confmatrix
schiData$PredictionsPerc=predict(diagnosisModel)
schiData$Predictions[schiData$PredictionsPerc>0.5]="0"
schiData$Predictions[schiData$PredictionsPerc<=0.5]="1"
confu<- confusionMatrix(data = schiData$Predictions, reference = schiData$diagnosis, positive = "1")
confusionMatrix(data = schiData$Predictions, reference = schiData$diagnosis, positive = "1")
#Lav predictions
schiData$PredictionsPerc <- predict(diagnosisModel)
#Make log into percent, to resemble probabilties.
#schiData$PredictionsPerc <- inv.logit(schiData$PredictionsLogit)
#Confmatrix
#schiData$PredictionsPerc=predict(diagnosisModel)
schiData$Predictions[schiData$PredictionsPerc>0]="0"
schiData$Predictions[schiData$PredictionsPerc<=0]="1"
confu<- confusionMatrix(data = schiData$Predictions, reference = schiData$diagnosis, positive = "1")
confu
e, rocCurve
install.packages("pROC"
, rocCurve
install.packages("pROC")
install.packages("pROC")
library(pROC)
schiData$diagnosis
rocCurve <- roc(response = str(schiData$diagnosis),   predictor = Data1$PredictionsPerc))
under curve, rocCurve
library(pROC)
rocCurve <- roc(response = str(schiData$diagnosis), predictor = schiData$PredictionsPerc))
```
rocCurve <- roc(response = str(schiData$diagnosis), predictor = schiData$PredictionsPerc))
rocCurve <- roc(response = schiData$diagnosis, predictor = schiData$PredictionsPerc))
```
rocCurve <- roc(response = schiData$diagnosis, predictor = schiData$PredictionsPerc)
rocCurve
rocCurve
rocCurveplot <- rocCurve + style_roc(theme = theme_grey, xlab = "1 - Specificity")
ggplot(test, aes(d = D, m = M1)) + geom_roc(n.cuts = 50, labels = FALSE)
ggplot(confu, aes(d = D, m = M1)) + geom_roc(n.cuts = 50, labels = FALSE)
ggplot(schiData, aes(d = schiData$diagnosis, m = confu)) + geom_roc(n.cuts = 50, labels = FALSE)
library(caret);library(gtools)
?caret
??caret
plot(rocCurve, legacy.aex = TRUE)
test$PredictionsLogit <- predict(glmModel, test)
#Make log into percent, to resemble proba
to resemble probabilties.
test$PredictionsPerc <- inv.logit(test$PredictionsLogit)
test$PredictionsPerc=predict(glmModel)
test$Predictions[test$PredictionsPerc>0]="0"
test$Predictions[test$PredictionsPerc<=0]="1"
testpred<- confusionMatrix(test = test$Predictions, reference = test$diagnosis, positive = "1")
_______________________________________________________________________________
#TEST model on test data
test$PredictionsPerc <- predict(glmModel, test)
#Make log into percent, to resemble probabilties.
test$PredictionsPerc <- inv.logit(test$PredictionsPerc)
test$PredictionsPerc=predict(glmModel)
test$Predictions[test$PredictionsPerc>0]="0"
test$Predictions[test$PredictionsPerc<=0]="1"
test$PredictionsPerc <- predict(glmModel, test)
test$PredictionsPerc=predict(glmModel)
test$Predictions[test$PredictionsPerc>0]="0"
test$Predictions[test$PredictionsPerc<=0]="1"
testpred<- confusionMatrix(test = test$Predictions, reference = test$diagnosis, positive = "1")
print(testpred)
testpred<- confusionMatrix(data = test$Predictions, reference = test$diagnosis, positive = "1")
print(testpred)
#Save model error as values
testvalues1[n]=(testpred)
trainvalues1[n]=(trainpred)
n = n+1
print(testvalues1)
names(coef(myMod))
names(coef(conf))
names(coef(confu))
names(coef(trainpred))
trainpred$terms[[3]]
trainpred$terms[[1]]
trainpred$terms[[2]]
all.vars(formula(trainpred))
formula(trainpred)
trainpred[3]
trainpred[2]
trainpred[1]
trainpred[3]
trainpred[4]
trainpred[5]
trainpred[6]
