---
title: "Assignment3_Part1_VoiceInSchizophrenia"
author: "Emily Holm Kelly"
date: "July 17, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Assignment 3 - Part 1 - Assessing voice in schizophrenia

Schizophrenia has been associated with "inappropriate" voice, sometimes monotone, sometimes croaky. A few studies indicate that pitch might be an index of schizophrenia. However, an ongoing meta-analysis of the literature (which you will have a go at in the last assignment) indicates that pitch mean and standard deviation are only weak indicators of diagnosis. Can we do better with our new fancy complex skills?

The corpus you are asked to analyse is a set of voice recordings from people with schizophrenia (just after first diagnosis) and 1-1 matched controls (on gender, age, education). Each participant watched 10 videos of triangles moving across the screen and had to describe them (so you have circa 10 recordings per person). I have already extracted the pitch once every 10 milliseconds and you will have to use this data to assess differences in the voice.

N.B. Question to be answered via email to Celine: can you characterize voice in schizophrenia as acoustically different? Report the methods you used to answer this question and the results from the analyses. Add a couple of lines trying to interpret the results (make sense of the difference). E.g. People with schizophrenia tend to have high-pitched voice, and present bigger swings in their prosody than controls. Add a couple of lines describing limitations of the data/analyses if any is relevant.

N.B. There are looots of files to be dealt with. Probably too many for your computer. This is a challenge for you. Some (complementary) possible strategies: You can select a subset of files only (and you have to justify your choice). You can learn how to use the apply() or map() functions. You can coordinate with classmates.


```{r}
#Set directory
setwd("~/R/R - Datascripts/Assignment 3")
#Load library
library(ggplot2);library(pastecs);library(rmarkdown);library(tidyr);
library(dplyr);library(QuantPsyc);library(VIF);library(stringr);library(tidytext);library(DHARMa)
library(lme4);library(lmerTest);library(psych);library(MuMIn);library(tidyverse);library(magrittr);library(Metrics);library(caret);library(simr);library(readtext);library(crqa);library(readr)
#Load dataset from part 1

DemoData = read.delim('DemoData.txt', sep = '.')
Pitch1 = read.table("~/R/R - Datascripts/Assignment 3/Pitch/Study1D0S101T1_f0.txt", header=T)


#Load data
files = list.files(path = "~/R/R - Datascripts/Assignment 3/Pitch",pattern="*.txt")#0 means control, 1 = Schizo. Number after 0 and 1 identifies two similiarly matched participants. They have similiar traits, so schizo is matched with a control.
#T 1, 2, 3 = video 1 they have to describe, video 2 etc



```

1. In the course of this assignment you have to first select one datafile and figure out how to:
- Extract "standard" descriptors of pitch: Mean, standard deviation, range
- Extract less "standard" descriptors of pitch you can think of (e.g. median, iqr, mean absoluted deviation, coefficient of variation)
- Extract "complex" descriptors: recurrence quantification analysis

```{r}

#Extract some standard(ish) stats
round(stat.desc(Pitch1), 3)
P_Mean = 139.920
P_SD = 31.385
P_Range = 142.010
P_median = 125.590
P_Coef.var = 0.224

#IQR (The interquartile range of an observation variable is the difference of its upper and lower quartiles. It is a measure of how far apart the middle portion of data spreads in value.) 
p_IQR = IQR(Pitch1$f0)
#42.137

SimplesNot <- cbind(P_Mean, P_SD, P_Range, P_median, P_Coef.var, p_IQR)
SimplesMat <- matrix(SimplesNot, nrow = 6, ncol = 1)
SimplesMat
row.names(SimplesMat) <- c("Mean", "SD", "Range", "Median", "Coef.var", "IQR")
colnames(SimplesMat) <- c("Standard Describtors")
SimplesMat

#Frequency median = 125,59, SE = 2,47, Coef.var = 0.224.

```
#______________________________Own random notes. Ignore__________________________________________
#Extract "complex descriptors".

#Delay parameter threshold(T); can be estimated using the mutual average information function.
#T is the basis of unfolding the one-dimensional time-series into a multidimensional phase-space.

#library(tseriesChaos)
# run Average Mutual Information
#mutual(Pitch1$f0, lag.max = 50)
#I chose the lowest value in my AMI plot to make the most conservative analysis. T = 22.

# Embedding parameter D; can be estimated using the false-nearest neighbor function.
# If D = 1, we do not need to embed.
# If D > 1, we want to unfold the one-dimensional time-series into as many dimensions so that we exhaust all information about higher-dimensional dynamics contained in the time-series, but not more.

# m: embedding dimension D
# d: delay T
# t: an additional parameter, the Theiler-window, that can help to increase the reliability of the false-nearest neighbor analysis and recurrence statistics by removing unwanted short-term temporal correlations.


# run false-nearestneighbor analysis
#fnn = false.nearest(Pitch1$f0, m=5, d=22, t=0)
#plot(fnn)

```{r}
#__________________________________CRQA _________________________________________________________
mlpar = list(lgM =  35, radiusspan = 400, radiussample = 10, normalize = 0, rescale = 1, mindiagline = 2, 
             minvertline = 2, tw = 0, whiteline = FALSE, recpt = FALSE, fnnpercent = 10, typeami = "maxlag")
optpar <- optimizeParam(Pitch1,Pitch1,mlpar); optpar

#I find the parameters for my crqa model:

Results <- try(crqa(Pitch1, Pitch1, embed = 3, delay = 30, radius = 0.5748302, normalize = 0, rescale = 2, mindiagline = 2, minvertline = 2))
Results

#$RR
#[1] 16.69536

#$DET
#[1] 99.26091

#$NRLINE
#[1] 401

#$maxL
#[1] 264

#$L
#[1] 28.80299

#$ENTR
#[1] 3.899081

#$rENTR
#[1] 0.8448493

#$LAM
#[1] 99.75077

#$TT
#[1] 41.01413


Simples <- matrix(Results,nrow = 7,ncol = 1)
row.names(Simples) <- c("RR", "DET", "NRLINE", "L", "ENTR", "LAM", "TT")
colnames(Simples) <- c("CRQA")
Simples

RP=Results$RP
RP = matrix(as.numeric(RP), nrow = ncol(RP)) 
cols = c("white","blue4")
image(RP, xlab = "", ylab = "", col = cols)
RP
#Delay
#Package, function Mutual(), tells muttual information. Tells how easy it is to predict the next datapoints. How strongly correlated two points in time. Trying to predict two points in the future, less correlation. So it should increase over time. We should try to find the optimal delay. Take the minium possible delay, really conservative and removes some data.

#Second way we look at when the slopes changes between data lines, so down, down, down, up. We stopÃ¥ here.Less conservative, keeps more data. 

#Use optimizeparam function. Will always pick the most conservative. Will give error embed*delay longer than tsm. We plot in timeseries in x-axis, but because we add a delay in y axis. We have to add x-time ontop of the x-axis time. We end up removing lots of data. If we use try() around it, it will run it and remove these.



```



```{r}
#______________________________________ CLASS NOTES ______________________________________________

#List all files

#Make loop
#The simplest loop

#Calculate mean, SD, and run crqa
# Mp = NULL
# SDp = NULL
# radius = NULL
# embed = NULL
# delay = NULL
# 
# N = 1
# 
# files <- list.files(path = "~/R/R - Datascripts/Assignment 3/Pitch", pattern="*.txt")
# 
# for (i in files) {
#   #Can use read_csv with ReadR package. Will read txt files aswell.
#   x = read.table(i, header = T)
#   #When did we record the pitch. We care about the F0 (pitch), we don't care about time. Drop time from x.
#   #x = x$F0
# }  
#   Mp[N]= mean(x, na.rm = T)
#   SDp[N] = SD(x,na.rm = T)
#   #It's best to start from one
#     N = N +1
#   #We want to save each loop in a dataframe: Mean and SD as columns.
#   #We first create these variables. 
#   #We create empty variables
#   
#   
#   #LOOK AT REGULAR EXPRESSIONS - Regex.
#   #Extract ID. Use a stringer extract strings, Use package StringR
#   #Create new empty variable 
#   particpant = Null
#   ID = str_extract(i, "S+\\d+")#in i find big S (string), like find S102 (study S102) \\ regular expression, search for digits, + means look for mulitple digtigts. Tell it look in files. Problem using S102, subjects ID's is not more meaningful as digits.
#   particpant[n] = str_extract(ID, "\\d+") #Use ID, it will look for ID numbers digits.
#   #use above code (kinda) to extract Diagnosis.
#   
#   mlpar = list(lgM =  35, radiusspan = 400, radiussample = 10, normalize = 0, rescale = 1,     mindiagline = 2, 
#              minvertline = 2, tw = 0, whiteline = FALSE, recpt = FALSE, fnnpercent = 10, typeami = "maxlag")
#   

#What does the CRQA do, and what does it mean.
# #RQUA, find Delay, Embed and Radius. Use optimize function optimizeparam()
# #One school of thought: Unfold the timephase in the best phasespace.
# #Other school of thought: You need to choose the same Delay, Embed and Radius for all timeseries. You want to maximise comparability of timeseries.
# #Both work.
#   
# #Always argue for your choice of extracting paramters!
#   
# #output of optimize. 
# #Issues with optimizeParam(). There's 3 dimensions Ex. Embed is longer than delay in timeseries. Embed could be 3, delay 50 and timeseries 1 sec.
# #We want to put timeseries on both axis. If it's a 100 secons, we have to throw everything above 100 on y and x-axis away. On the third dimension, we have to delay. Problem we want to set it to 101, but there is none, so it throws everything away.
# #There is a paramter in optimize lgM, means lag maximum. Use 15. They found the lag by testing numbers in files above 100, that kept most data. Ex. if you record a voice with a microphone, the vibrations from first test could continue slightly into the second, polluting data. So you find a cutoff.
# 
# #When we look at recurrence plot thats' either blank or black, we can't read anything from it. 
# #Recurrence rate is discontinous. Sometimes you can't optimize paramters, you can try and relax the min and max radius. Less precise comparability between min and max if there's a larger difference.
# #Use min.Rec = 3 and max.rec = 5
# #If we look at the plot and get a black square around 0.4, 
#   #A = optimizeParam(x,x, mlpar)
# #If you get embed*delay error shows up, use try(). This makes the loop continue and doesn't crash. You want the loop to keep running if it gets an error. 
#   A = try(optimizeParam(x,x,mlpar))
#   if(length(A)<2{
#     delay[N] = NA #Delay of datapoints
#     embed[N] = NA
#     radius[N] = NA
#   })
#     else(delay[N] = A$Delay)
# }
# #After loop write into dataframe
# Df = data.frame(participant, Mp, SDp)
# 
#     #Save delay and embed and radius into a dataframe. Now you have optimal paramters.
#     #You now find a delay, embed and radius for all files.
#     #So find median for all delays
#     Delay = Mean(Df$Delay, na.rm = TRUE)
#     #You can build a second loop just find CRQA information and save into dataframe for each files
# 
# 
# #After loop write into dataframe.
# 
# #Second loop would look like this
# for (i in files) {
#   #Can use read_csv with ReadR package. Will read txt files aswell.
#   x = read.table(i)
#   x = x$F0
#   # When did we record the pitch. We care about the F0 (pitch), we don't care about time. Drop time from x.
#   # Use paramters found in the first loop
#   CRQA(x,x...)
#   RR[N] = A$Rec
#   DET[N] = A$DET
#   
#   # Write into a csv file
#   write.csv(dataframe, file = "filenamewhatever.csv")
# 
# }

```

2. Second you will have to turn the code into a function and loop through all the files (or even better use apply/sapply/lapply)
- Remember to extract the relevant information from the file names (Participant, Diagnosis, Trial, Study)

```{r}

#Extract list of files
files = list.files(path = "~/R/R - Datascripts/Assignment 3/Pitch",pattern="*.txt")
#setWD
setwd("~/R/R - Datascripts/Assignment 3/Pitch")

participant = NULL
diagnosis = NULL
trial = NULL
study = NULL
delay = NULL
radius = NULL
embed = NULL




n = 1




#Extract optimal parameters
for (file in files){
  #print(file)
  
  
  #read the specific file
  tempFile = read.table(file, header = T)
  
  #get participant number information
  #would like to extract seperate participant, trial and diagnosis info
  study[n] = substring(file, 6, 6)
  diagnosis[n] = substring(file, 8, 8)
  participant[n] = substring(sub("T.*", "", file),8)
  trial[n] = sub(".T*", "", sub("\\_.*", "", sub("^[^T]*", "", file)))
  
  
  #optimizeparam functions
  par = list(lgM = 50, steps = seq(1, 6, 1), radiusspan = 100, radiussample = 40, normalize = 0, rescale = 0, mindiagline = 2, minvertline = 2, tw = 0, whiteline = F, recpt = FALSE, fnnpercent = 10, typeami = "mindip")
  ans = try(optimizeParam(tempFile$f0, tempFile$f0, par))
  
  #print(ans)
  
  #if statement: If having problem with optimizeparam, it will append NA
  if (length(ans) > 1){
    radius[n] = ans[1]
    embed[n] = ans[2]
    delay[n] = ans[3]
    }
  
  else {
    radius[n] = NA
    embed[n] = NA
    delay[n] = NA
    
  }
  
  n = n+1
  print(n)
  
}




#Need to unlist
delay = unlist(delay)
embed = unlist(embed)
radius = unlist(radius)


df = data.frame(participant, diagnosis, study, trial, embed, delay, radius)



#Write to datafile to avoid looping through all of them again
write.csv(df, file = "dataExtractSchizo.csv", row.names = F)


```


Make the loop for your CRQA


```{r}
#setWD for chunk
setwd("~/R/R - Datascripts/Assignment 3/Pitch")
#calculate median delay, radius and embed
radiusOptimal = median(radius, na.rm = T)
embedOptimal = median(embed, na.rm = T)
delayOptimal = median(delay, na.rm = T)


#crqaextract
N = 1
rqa_RR = NULL
rqa_DET = NULL
rqa_NRLINE = NULL
rqa_maxL = NULL
rqa_L = NULL
rqa_ENTR = NULL
rqa_rENTR = NULL
rqa_LAM = NULL
rqa_TT = NULL
rqa_RP = NULL


for (file in files){
  print(file)
  
  #read the specific file
  tempFile = read.table(file, header = T)
  
  #Make CRQA
  results = try(crqa(tempFile$f0, tempFile$f0, delay = delayOptimal, embed = embedOptimal, radius = radiusOptimal, normalize = 0, rescale = 0, mindiagline = 2, minvertline = 2))
  # 
  # mlpar = list(lgM =  35, radiusspan = 400, radiussample = 10, normalize = 0, rescale = 1,     mindiagline = 2, 
  #            minvertline = 2, tw = 0, whiteline = FALSE, recpt = FALSE, fnnpercent = 10, typeami = "maxlag")
  
  if (length(results) > 1){
    #Write to lists
    rqa_RR[N] = results[1]
    rqa_DET[N] = results[2]
    rqa_NRLINE[N] = results[3]
    rqa_maxL[N] = results[4]
    rqa_L[N] = results[5]
    rqa_ENTR[N] = results[6]
    rqa_rENTR[N] = results[7]
    rqa_LAM[N] = results[8]
    rqa_TT[N] = results[9]
    rqa_RP[N] = results[10]
  }
  else{
    rqa_RR[N] = NA
    rqa_DET[N] = NA
    rqa_NRLINE[N] = NA
    rqa_maxL[N] = NA
    rqa_L[N] = NA
    rqa_ENTR[N] = NA
    rqa_rENTR[N] = NA
    rqa_LAM[N] = NA
    rqa_TT[N] = NA
    rqa_RP[N] = NA
  }
  
  
  N = N+1
  
  }

#Unlist variables
rqa_RR = unlist(rqa_RR)
rqa_DET = unlist(rqa_DET)
rqa_NRLINE = unlist(rqa_NRLINE)
rqa_maxL = unlist(rqa_maxL)
rqa_L = unlist(rqa_L)
rqa_ENTR = unlist(rqa_ENTR)
rqa_LAM = unlist(rqa_LAM)
rqa_TT = unlist(rqa_TT)


df_new = data.frame(df, rqa_RR, rqa_DET, rqa_NRLINE, rqa_maxL, rqa_L, rqa_ENTR, rqa_LAM, rqa_TT)



```


Loop for standard descriptors
```{r}
#setwd
("~/R/R - Datascripts/Assignment 3/Pitch")
mean = NULL
median = NULL
stdDev = NULL
range = NULL
IQR = NULL
coefOfVar = NULL
meanAbsDev = NULL

N = 1

for (file in files){
  print(file)
  
  #read the specific file
  tempFile = read.table(file, header = T)
  
  #Mean
  mean[N] = mean(tempFile$f0)
  
  #median
  median [N] = median(tempFile$f0)
  
  #stdDev
  stdDev[N] = sd(tempFile$f0)
  
  #range
  range[N] = max(range(tempFile$f0))-min(range(tempFile$f0))
  
  #Interquartile range
  IQR[N] = IQR(tempFile$f0)
  
  #CV
  coefOfVar[N] = stdDev[N]/mean[N]*100
  
  meanAbsDev[N] = mad(tempFile$f0)
  
  N = N+1
  
}


df = data.frame(df_new, mean, median, stdDev, range, IQR, coefOfVar, meanAbsDev)

#write to CSV
write.csv(df, file = "dataExtractSchizo.csv", row.names = F)

```

3. Make one model per acoustic feature and test whether you can observe significant difference due to Diagnosis. Tip: Which other fixed factors should you control for (that is, include in the model)? Which random ones?
- Bonus points: cross-validate the model and report the betas and standard errors from all rounds to get an idea of how robust the estimates are. 
3a. Is study a significant predictor in these models? What should you infer from this? Does study interact with diagnosis? What should you infer from this?

```{r}
#Load in newly made datafile for ease
setwd("~/R/R - Datascripts/Assignment 3")
df3 = read.delim('dataExtractSchizo.csv', sep = ',')
3.2881

#Use scale() for fixed effects

#RR
pitchRR <- lmer(rqa_RR ~ diagnosis + scale(trial) + scale(study) + (1|study) + (1+diagnosis|participant), df3, REML = FALSE)
summary(pitchRR)



#DET
pitchDET <- lmer(rqa_DET ~ diagnosis + scale(trial) + scale(study) + (1|study) + (1+diagnosis|participant), df3, REML = FALSE)
summary(pitchDET)



#ENTR
pitchENTR <- lmerTest(rqa_ENTR ~ diagnosis + scale(trial) + scale(study) + (1|study) + (1+diagnosis|participant), df3, REML = FALSE)
summary(pitchENTR)


#L
pitchL <- lmer(rqa_L ~ diagnosis + scale(trial) + scale(study) + (1|study) + (1+diagnosis|participant), df3, REML = FALSE)
summary(pitchL)

sjt.lmer(pitchL)


#LAM
pitchLAM <- lmer(rqa_LAM ~ diagnosis + scale(trial) + scale(study) + (1|study) + (1+diagnosis|participant), df3, REML = FALSE)
summary(pitchLAM)


#maxL
pitchmaxL <- lmer(rqa_maxL ~ diagnosis + scale(trial) + scale(study) + (1|study) + (1+diagnosis|participant), df3, REML = FALSE)
summary(pitchmaxL)



#NRLINE
pitchNRLINE <- lmer(rqa_NRLINE ~ diagnosis + scale(trial) + scale(study) + (1|study) + (1+diagnosis|participant), df3, REML = FALSE)
summary(pitchNRLINE)


#ENTR
pitchENTR <- lmer(rqa_ENTR ~ diagnosis + scale(trial) + scale(study) + (1|study) + (1+diagnosis|participant), df3, REML = FALSE)
summary(pitchENTR)


#TT
pitchTT <- lmer(rqa_TT ~ diagnosis + scale(trial) + scale(study) + (1|study) + (1+diagnosis|participant), df3, REML = FALSE)
summary(pitchTT)


# load required packages
library(sjPlot) # table functions
library(sjmisc) # sample data


sjt.lmer(pitchRR, pitchDET, pitchENTR,  show.std = FALSE, show.aic = TRUE, show.r2 = FALSE, emph.p = TRUE,  digits.p = 3,show.se = TRUE,digits.se = 3,show.re.var = TRUE, show.icc = FALSE,
         show.dev = TRUE,  digits.est = 3, digits.summary = 3)
        

sjt.lmer(pitchL, pitchLAM, pitchmaxL,  show.std = FALSE, show.aic = TRUE, show.r2 = FALSE, emph.p = TRUE,  digits.p = 3,show.se = TRUE,digits.se = 3,show.re.var = TRUE, show.icc = FALSE,
         show.dev = TRUE,  digits.est = 3, digits.summary = 3)


sjt.lmer(pitchNRLINE, pitchTT,  show.std = FALSE, show.aic = TRUE, show.r2 = FALSE, emph.p = TRUE,  digits.p = 3,show.se = TRUE,digits.se = 3,show.re.var = TRUE, show.icc = FALSE,
         show.dev = TRUE,  digits.est = 3, digits.summary = 3)
        
```




4. Bonus Question: Compare effect size of diagnosis across the different measures. Which measure seems most sensitive?
- Tip: to compare across measures you need to put all of them on the same scale, that is, you need to "standardize" them (z-score)

5. Bonus question. In the Clinical Info file you have additional information about the participants. Which additional parameters (e.g. age, gender) should we control for? Report the effects.

6. Write a paragraph reporting methods and results

[Next assignment: can we use these measures to build a tool that diagnoses people from voice only?]

## N.B. Remember to save the acoustic features of voice in a separate file, so to be able to load them next time